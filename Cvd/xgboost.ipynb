{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('CVD dataset2.csv')\n",
    "data=dataset.iloc[:, :].values\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 16].values\n",
    "# X = dataset.iloc[:, [ 0, 1, 2, 5, 10, 11, 13, 15]].values\n",
    "\n",
    "rows = len(data)    # 3 rows in your example\n",
    "cols = len(data[0])\n",
    "print(rows)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "dataNoCvd = data[~(data[:,16] > 0.0)]\n",
    "dataCvd = data[~(data[:,16] < 1.0)]\n",
    "rowsNoCvd = len(dataNoCvd)    \n",
    "rowsCvd = len(dataCvd)\n",
    "print(rowsNoCvd)\n",
    "print(rowsCvd)\n",
    "# print(dataNoCvd)\n",
    "# print(dataCvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NoCvd_limitsArray(i,DownNoCvd, UpNoCvd, fold_NoCvd_total, fold_NoCvd_residue):\n",
    "    if i>0 :\n",
    "        DownNoCvd = UpNoCvd\n",
    "        UpNoCvd= fold_NoCvd_total+UpNoCvd\n",
    "    if i < fold_NoCvd_residue :\n",
    "        UpNoCvd+= 1\n",
    "#     print(\"NoCvd limits, Down :\",DownNoCvd,\"Up \",UpNoCvd)\n",
    "    return   DownNoCvd, UpNoCvd   \n",
    " \n",
    "def find_Cvd_limitsArray(i,DownCvd, UpCvd, fold_Cvd_total, fold_Cvd_residue,cv):\n",
    "    if i>0 :\n",
    "        DownCvd = UpCvd\n",
    "        UpCvd= fold_Cvd_total+UpCvd\n",
    "    if i >= cv - fold_Cvd_residue :\n",
    "         UpCvd+= 1     \n",
    "#     print(\"Cvd limits, Down :\",DownCvd,\"Up \",UpCvd)\n",
    "    return   DownCvd, UpCvd  \n",
    "\n",
    "def find_testValSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd):\n",
    "    temp1=dataNoCvd[DownNoCvd:UpNoCvd,:]\n",
    "    temp2=dataCvd[DownCvd:UpCvd,:]\n",
    "    temp3=np.concatenate((temp1, temp2))\n",
    "#     print(len(temp1),\"  \",len(temp2),\"  \",len(temp3))\n",
    "    return temp3\n",
    "\n",
    "def find_trainSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd):\n",
    "    temp1 = np.delete(dataNoCvd, slice(DownNoCvd, UpNoCvd), axis=0)\n",
    "    temp2 = np.delete(dataCvd, slice(DownCvd, UpCvd), axis=0)\n",
    "    temp3 = np.concatenate((temp1, temp2))\n",
    "#     print(len(temp1),\"  \",len(temp2),\"  \",len(temp3))\n",
    "    return temp1, temp2, temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_sets(cv,dataNoCvd,dataCvd,val_ratio):\n",
    "    test_total = []\n",
    "    train_total = []\n",
    "    train_total_Cvd = []\n",
    "    train_total_NoCvd = []\n",
    "    validation_total = []\n",
    "    \n",
    "    rowsNoCvd = len(dataNoCvd)    \n",
    "    rowsCvd = len(dataCvd)\n",
    "\n",
    "    fold_Cvd_total = rowsCvd//cv\n",
    "    fold_Cvd_residue= rowsCvd%cv\n",
    "    print(\"fold_Cvd_total  :\",fold_Cvd_total,\" fold_Cvd_residue  :\",fold_Cvd_residue)\n",
    "\n",
    "    fold_NoCvd_total = rowsNoCvd//cv\n",
    "    fold_NoCvd_residue= rowsNoCvd%cv\n",
    "    print(\"fold_NoCvd_total:\",fold_NoCvd_total,\"fold_NoCvd_residue:\",fold_NoCvd_residue)\n",
    "    \n",
    "    Cvd_val = round(504*val_ratio*(rowsCvd/len(data)))\n",
    "    noCvd_val = round(504*val_ratio)-Cvd_val\n",
    "    print(noCvd_val)\n",
    "    \n",
    "    DownNoCvd=0\n",
    "    DownCvd=0\n",
    "    UpNoCvd = fold_NoCvd_total\n",
    "    UpCvd = fold_Cvd_total\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_val = []\n",
    "        y_val = []\n",
    "#         print(\"============\",i,\"==============\")\n",
    "        DownNoCvd, UpNoCvd = find_NoCvd_limitsArray(i, DownNoCvd, UpNoCvd, fold_NoCvd_total, fold_NoCvd_residue)\n",
    "        DownCvd, UpCvd = find_Cvd_limitsArray(i, DownCvd, UpCvd, fold_Cvd_total, fold_Cvd_residue,cv)\n",
    "#         print(DownNoCvd,UpNoCvd,DownCvd,UpCvd)\n",
    "        testSubset_total = find_testValSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd)\n",
    "        if i!=9:\n",
    "#             print(UpNoCvd,UpNoCvd+noCvd_val,UpCvd,UpCvd+Cvd_val)\n",
    "            validationSubset_total = find_testValSubset(UpNoCvd,UpNoCvd+noCvd_val,UpCvd,UpCvd+Cvd_val)\n",
    "#             print(DownNoCvd,UpNoCvd+noCvd_val,DownCvd,UpCvd+Cvd_val)\n",
    "            trainSubset_NoCvd ,trainSubset_Cvd ,trainSubset_total = find_trainSubset(DownNoCvd,UpNoCvd+noCvd_val,DownCvd,UpCvd+Cvd_val)\n",
    "        else:\n",
    "#             print(DownNoCvd-noCvd_val,DownNoCvd,DownCvd-Cvd_val,DownCvd)\n",
    "            validationSubset_total = find_testValSubset(DownNoCvd-noCvd_val,DownNoCvd,DownCvd-Cvd_val,DownCvd)\n",
    "#             print(DownNoCvd-noCvd_val,UpNoCvd,DownCvd-Cvd_val,UpCvd)\n",
    "            trainSubset_NoCvd ,trainSubset_Cvd ,trainSubset_total = find_trainSubset(DownNoCvd-noCvd_val,UpNoCvd,DownCvd-Cvd_val,UpCvd)\n",
    "    #creating X_train, y_train, X_test, y_test\n",
    "        X_test.append(np.delete(testSubset_total, 16, axis=1))\n",
    "        y_test_temp = np.delete(testSubset_total, slice(0, 16), axis=1)\n",
    "        y_test.append(np.reshape(y_test_temp, len(y_test_temp)))\n",
    "        X_test_temp = np.array(X_test)\n",
    "        X_test = X_test_temp[0]\n",
    "        y_test_temp = np.array(y_test)\n",
    "        y_test = y_test_temp[0]\n",
    "        \n",
    "        X_val.append(np.delete(validationSubset_total, 16, axis=1))\n",
    "        y_val_temp = np.delete(validationSubset_total, slice(0, 16), axis=1)\n",
    "        y_val.append(np.reshape(y_val_temp, len(y_val_temp)))\n",
    "        X_val_temp = np.array(X_val)\n",
    "        X_val = X_val_temp[0]\n",
    "        y_val_temp = np.array(y_val)\n",
    "        y_val = y_val_temp[0]\n",
    "        \n",
    "        X_train.append(np.delete(trainSubset_total, 16, axis=1))\n",
    "        y_train_temp = np.delete(trainSubset_total, slice(0, 16), axis=1)\n",
    "        y_train.append(np.reshape(y_train_temp, len(y_train_temp)))\n",
    "        X_train_temp = np.array(X_train)\n",
    "        X_train = X_train_temp[0]\n",
    "        y_train_temp = np.array(y_train)\n",
    "        y_train = y_train_temp[0]\n",
    "        \n",
    "    #add every subset in a list so we can handle thm later \n",
    "        test_total.append([X_test,y_test])\n",
    "        validation_total.append([X_val,y_val])\n",
    "        train_total.append([X_train,y_train]) \n",
    "        train_total_NoCvd.append(trainSubset_NoCvd)\n",
    "        train_total_Cvd.append(trainSubset_Cvd)\n",
    "    return train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_Cvd_total  : 4  fold_Cvd_residue  : 1\n",
      "fold_NoCvd_total: 51 fold_NoCvd_residue: 9\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd = create_train_test_sets(10,dataNoCvd,dataCvd,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07048458149779736\n",
      "ratio in test set: 0.08928571428571429\n",
      "ratio in validation set: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Chech ratio in each train and test set\n",
    "def find_ratio(index_list):\n",
    "    one = 0\n",
    "    lenght=len(index_list[0])\n",
    "    for i in range(lenght):\n",
    "#         print(index_list[1])\n",
    "        if index_list[1][i] == 1.0 :\n",
    "            one+= 1\n",
    "    ratio = one/lenght\n",
    "    return ratio\n",
    "\n",
    "for i in range(10):\n",
    "    print(len(train_total[i][0]))\n",
    "    ratio = find_ratio(train_total[i])\n",
    "    print(\"ratio in train set:\", ratio)\n",
    "    ratio = find_ratio(test_total[i])\n",
    "    print(\"ratio in test set:\", ratio)\n",
    "    ratio = find_ratio(validation_total[i])\n",
    "    print(\"ratio in validation set:\", ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix,roc_curve, roc_auc_score, accuracy_score\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def my_cross_val( cv, train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd,params):\n",
    "    accuracy = []\n",
    "    specificity = []\n",
    "    sensitivity = []\n",
    "    auc = []\n",
    "    \n",
    "    # print(X)\n",
    "    for i in range(cv):\n",
    "#         X_train = train_total[i][0]\n",
    "#         y_train = train_total[i][1]\n",
    "        X_test = test_total[i][0]\n",
    "        y_test = test_total[i][1]\n",
    "        \n",
    "        classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=params[5],\n",
    "                  colsample_bynode=1, colsample_bytree=params[8], gamma=params[4],\n",
    "                  learning_rate=params[0], max_delta_step=0, max_depth=params[1],\n",
    "                  min_child_weight=params[3], missing=None, n_estimators=params[2], n_jobs=1,\n",
    "                  nthread=None, objective='binary:logistic', random_state=0,\n",
    "                  reg_alpha=params[9], reg_lambda=params[6], scale_pos_weight=params[7], seed=None,\n",
    "                  silent=None, subsample=params[10], verbosity=1)\n",
    "        \n",
    "        X_train = train_total[i][0]\n",
    "        y_train = train_total[i][1]\n",
    "        \n",
    "        X_val = validation_total[i][0]\n",
    "        y_val = validation_total[i][1]\n",
    "        \n",
    "        eval_set  = [(X_train,y_train), (X_val,y_val)]\n",
    "        \n",
    "        classifier.fit( X_train, y_train, eval_set=eval_set, eval_metric=\"auc\", early_stopping_rounds=50,verbose = False )\n",
    "\n",
    "        \n",
    "        \n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "    #     print(cm)\n",
    "\n",
    "        total1=sum(sum(cm))\n",
    "        #####from confusion matrix calculate accuracy\n",
    "        accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "    #   print ('Accuracy : ', accuracy1)\n",
    "\n",
    "        specificity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    #   print('Specificity : ', specificity1 )\n",
    "\n",
    "        sensitivity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    #   print('Sensitivity : ', sensitivity1)\n",
    "        \n",
    "#         y = np.array(y_test)\n",
    "#         pred = np.array(y_pred)\n",
    "#         fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
    "#         auc1 = metrics.auc(fpr, tpr)\n",
    "        \n",
    "        auc1 = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "        accuracy.append(accuracy1)\n",
    "        specificity.append(specificity1)\n",
    "        sensitivity.append(sensitivity1) \n",
    "        auc.append(auc1)\n",
    "    return accuracy, specificity, sensitivity, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_comb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d4002574eb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_comb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cross_val\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total_NoCvd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total_Cvd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_comb' is not defined"
     ]
    }
   ],
   "source": [
    "comb = compute_comb(params)\n",
    "print(comb[0])\n",
    "accuracy, specificity, sensitivity, auc = my_cross_val( 10, train_total, test_total, train_total_NoCvd, train_total_Cvd,comb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fec754a471de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(mean(accuracy))\n",
    "print(mean(specificity))\n",
    "print(mean(sensitivity))\n",
    "print(mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-all-possible-permutations-of-n-lists/\n",
    "\n",
    "def compute_comb(params):\n",
    "    \n",
    "    # initializing lists \n",
    "    list1 = params.get(\"learning_rate\")\n",
    "    list2 = params.get(\"max_depth\")\n",
    "    list3 = params.get(\"n_estimators\") \n",
    "    list4 = params.get(\"min_child_weight\")\n",
    "    list5 = params.get(\"gamma\")    \n",
    "    list6 = params.get(\"colsample_bylevel\")\n",
    "    list7 = params.get(\"reg_lambda\") \n",
    "    list8 = params.get(\"scale_pos_weight\")\n",
    "    list9 = params.get(\"colsample_bytree\")\n",
    "    list10 = params.get(\"reg_alpha\")\n",
    "    list11 = params.get(\"subsample\")\n",
    "    \n",
    "\n",
    "#     # printing lists  \n",
    "#     print (\"The original lists are : \" + str(list1) +\n",
    "#                                    \" \" + str(list2) + \n",
    "#                                    \" \" + str(list3) + \n",
    "#                                    \" \" + str(list4) + \n",
    "#                                    \" \" + str(list5) + \n",
    "#                                    \" \" + str(list6) +\n",
    "#                                    \" \" + str(list7) +\n",
    "#                                    \" \" + str(list8)) \n",
    "\n",
    "    # using list comprehension  \n",
    "    # to compute all possible permutations \n",
    "    res = [[i, j, k, l, m, n, o, p,q,r,s] for i in list1  \n",
    "                                          for j in list2 \n",
    "                                          for k in list3 \n",
    "                                          for l in list4 \n",
    "                                          for m in list5 \n",
    "                                          for n in list6 \n",
    "                                          for o in list7\n",
    "                                          for p in list8\n",
    "                                          for q in list9\n",
    "                                          for r in list10\n",
    "                                          for s in list11] \n",
    "\n",
    "    # printing result \n",
    "#     print (\"All possible permutations are : \" +  str(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class style:\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix,roc_curve, roc_auc_score, accuracy_score\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "from statistics import mean\n",
    "\n",
    "def gridsearch(params):\n",
    "    max_sens = 0\n",
    "    max_spes = 0\n",
    "    max_acc = 0\n",
    "    best_params = []\n",
    "    max_params = []\n",
    "    max_auc = 0\n",
    "    combs = compute_comb(params)\n",
    "    print(len(combs))\n",
    "    for j in range(len(combs)):\n",
    "        print (j, end=\"\\r\")\n",
    "        accuracy, specificity, sensitivity, auc = my_cross_val( 10, train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd,combs[j])\n",
    "        if mean(auc)>0.65:\n",
    "            print(style.BOLD + \"----------------------------------------------------------------\"+ style.END)\n",
    "            print(combs[j])\n",
    "            print (style.BOLD + 'accuracy    ' + style.END, mean(accuracy))\n",
    "            print (style.BOLD + 'specificity ' + style.END, mean(specificity))\n",
    "            print (style.BOLD + 'sensitivity ' + style.END, mean(sensitivity))\n",
    "            print (style.BOLD + 'auc         ' + style.END, mean(auc))\n",
    "            print(style.BOLD + \"----------------------------------------------------------------\"+ style.END)\n",
    "#         else:\n",
    "#             print(combs[j])\n",
    "#             print(\"accuracy    \",mean(accuracy))\n",
    "#             print(\"specificity \",mean(specificity))\n",
    "#             print(\"sensitivity \",mean(sensitivity))\n",
    "#             print(\"auc         \",mean(auc))\n",
    "            \n",
    "        best_params.append([combs[j],mean(accuracy),mean(specificity),mean(sensitivity),mean(auc)])\n",
    "        if mean(auc)> max_auc:\n",
    "            max_sens = mean(sensitivity)\n",
    "            max_spes = mean(specificity)\n",
    "            max_acc = mean(accuracy)\n",
    "            max_auc = mean(auc)\n",
    "            max_params = combs[j]\n",
    "    return max_sens, max_params, max_spes, max_acc, max_auc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Αποτέλεσμα της gridsearch με τις ακόλουθες παραμέτρους, γίνονται print όλα και αυτά που ικανοποιούν την συνθήκη : if mean(sensitivity)> 0.5 and mean(specificity)>0.6 and mean(accuracy)>0.6 and mean(auc)>0.5 είναι με bold και μεταξύ γραμμών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.3],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[3,4,5],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 2, 1000, 1, 0, 0.75, 1.5, 5, 1.0, 0.2, 1.0]\n",
      "0.925\n",
      "0.9865384615384615\n",
      "0.145\n",
      "0.5657692307692308\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.3, 2, 1000, 1, 0, 0.75, 1.5, 5, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.925\n",
      "spes     : 0.9865384615384615\n",
      "sens     : 0.145\n",
      "auc      : 0.5657692307692308\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 2, 1000, 1, 0.5, 0.75, 1.5, 5, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.925\n",
      "spes     : 0.9865384615384615\n",
      "sens     : 0.145\n",
      "auc      : 0.5657692307692308\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 2, 1000, 1, 1, 0.75, 1.5, 5, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.925\n",
      "spes     : 0.9865384615384615\n",
      "sens     : 0.145\n",
      "auc      : 0.5657692307692308\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 3, 1000, 1, 1, 0.5, 2, 5, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.9035714285714286\n",
      "spes     : 0.9614253393665159\n",
      "sens     : 0.17\n",
      "auc      : 0.565712669683258\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 3, 1000, 3, 1, 0.75, 2, 5, 1.0, 0.2, 0.8]\n",
      "accuracy : 0.8982142857142857\n",
      "spes     : 0.9557315233785821\n",
      "sens     : 0.17\n",
      "auc      : 0.562865761689291\n",
      "------------------------------------------------\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.56:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.3],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[6,7,8],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43740\n",
      "43739\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 3, 1000, 4, 1, 0.5, 1.5, 7, 0.5, 0.05, 0.8]\n",
      "0.8678571428571429\n",
      "0.9114630467571644\n",
      "0.32\n",
      "0.6157315233785822\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.3, 3, 1000, 3, 0.5, 0.5, 1, 6, 0.5, 0, 0.8]\n",
      "accuracy : 0.8875\n",
      "spes     : 0.9345776772247361\n",
      "sens     : 0.295\n",
      "auc      : 0.614788838612368\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 3, 1000, 4, 0, 0.5, 1.5, 7, 0.5, 0.1, 0.8]\n",
      "accuracy : 0.8625\n",
      "spes     : 0.9057315233785822\n",
      "sens     : 0.32\n",
      "auc      : 0.6128657616892911\n",
      "------------------------------------------------\n",
      "parameters : [0.3, 3, 1000, 4, 1, 0.5, 1.5, 7, 0.5, 0.05, 0.8]\n",
      "accuracy : 0.8678571428571429\n",
      "spes     : 0.9114630467571644\n",
      "sens     : 0.32\n",
      "auc      : 0.6157315233785822\n",
      "------------------------------------------------\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.61:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.3],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[5,6],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[6,7,8],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21870\n",
      "21869\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 3, 1000, 5, 1, 0.5, 2, 8, 1.0, 0.2, 1.0]\n",
      "0.8642857142857143\n",
      "0.9076168929110106\n",
      "0.315\n",
      "0.6113084464555053\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.3, 3, 1000, 5, 1, 0.5, 2, 8, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.8642857142857143\n",
      "spes     : 0.9076168929110106\n",
      "sens     : 0.315\n",
      "auc      : 0.6113084464555053\n",
      "------------------------------------------------\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.61:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.1],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4,5],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[3,4,5,6],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62208\n"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 4, 1000, 1, 1, 0.5, 1, 6, 0.75, 0.2, 0.9]\n",
      "0.8892857142857142\n",
      "0.9403469079939668\n",
      "0.245\n",
      "0.5926734539969833\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.1, 4, 1000, 1, 1, 0.5, 1, 6, 0.75, 0, 0.9]\n",
      "accuracy : 0.8857142857142857\n",
      "spes     : 0.9364253393665158\n",
      "sens     : 0.245\n",
      "auc      : 0.5907126696832579\n",
      "------------------------------------------------\n",
      "parameters : [0.1, 4, 1000, 1, 1, 0.5, 1, 6, 0.75, 0.2, 0.9]\n",
      "accuracy : 0.8892857142857142\n",
      "spes     : 0.9403469079939668\n",
      "sens     : 0.245\n",
      "auc      : 0.5926734539969833\n",
      "------------------------------------------------\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.59:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.1],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[3,4,5,6],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4,5,6],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69984\n",
      "69983\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.4],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4,5],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93312\n",
      "93311\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 3, 1000, 4, 0.5, 0.5, 1, 6, 0.5, 0.2, 0.8]\n",
      "0.8696428571428572\n",
      "0.9132730015082956\n",
      "0.315\n",
      "0.6141365007541478\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.4, 3, 1000, 4, 0.5, 0.5, 1, 6, 0.5, 0.2, 0.8]\n",
      "accuracy : 0.8696428571428572\n",
      "spes     : 0.9132730015082956\n",
      "sens     : 0.315\n",
      "auc      : 0.6141365007541478\n",
      "------------------------------------------------\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.61:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.4],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4,5],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[5,6],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46656\n",
      "44174\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 5, 1000, 5, 1, 0.5, 1.5, 8, 1.0, 0.2, 1.0]\n",
      "0.8660714285714286\n",
      "0.9095022624434389\n",
      "0.32\n",
      "0.6147511312217194\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.4, 3, 1000, 5, 0, 0.5, 2, 9, 1.0, 0.1, 1.0]\n",
      "accuracy : 0.8160714285714286\n",
      "spes     : 0.8518476621417798\n",
      "sens     : 0.37\n",
      "auc      : 0.6109238310708899\n",
      "------------------------------------------------\n",
      "parameters : [0.4, 3, 1000, 5, 0.5, 0.5, 2, 9, 1.0, 0, 1.0]\n",
      "accuracy : 0.8410714285714286\n",
      "spes     : 0.8806938159879336\n",
      "sens     : 0.345\n",
      "auc      : 0.6128469079939668\n",
      "------------------------------------------------\n",
      "parameters : [0.4, 3, 1000, 5, 0.5, 0.5, 2, 9, 1.0, 0.1, 1.0]\n",
      "accuracy : 0.8214285714285714\n",
      "spes     : 0.8576168929110105\n",
      "sens     : 0.37\n",
      "auc      : 0.6138084464555053\n",
      "------------------------------------------------\n",
      "parameters : [0.4, 5, 1000, 5, 0, 0.5, 1.5, 6, 1.0, 0.3, 0.9]\n",
      "accuracy : 0.8803571428571428\n",
      "spes     : 0.9268853695324284\n",
      "sens     : 0.295\n",
      "auc      : 0.6109426847662142\n",
      "------------------------------------------------\n",
      "parameters : [0.4, 5, 1000, 5, 1, 0.5, 1.5, 8, 1.0, 0.2, 1.0]\n",
      "accuracy : 0.8660714285714286\n",
      "spes     : 0.9095022624434389\n",
      "sens     : 0.32\n",
      "auc      : 0.6147511312217194\n",
      "------------------------------------------------\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.61:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.4],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[6,7],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[5,6],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23328\n",
      "23327\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 6, 1000, 6, 0.5, 0.5, 1, 6, 1.0, 0, 0.9]\n",
      "0.8821428571428571\n",
      "0.9306561085972851\n",
      "0.27\n",
      "0.6003280542986426\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.4, 6, 1000, 6, 0.5, 0.5, 1, 6, 1.0, 0, 0.9]\n",
      "accuracy : 0.8821428571428571\n",
      "spes     : 0.9306561085972851\n",
      "sens     : 0.27\n",
      "auc      : 0.6003280542986426\n",
      "------------------------------------------------\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.6:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.2],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4,5],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93312\n",
      "93311\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 3, 1000, 1, 0.5, 0.75, 1, 9, 0.5, 0.05, 0.8]\n",
      "0.8517857142857143\n",
      "0.8901960784313725\n",
      "0.365\n",
      "0.6275980392156862\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.2, 3, 1000, 1, 0.5, 0.75, 1, 9, 0.5, 0.05, 0.8]\n",
      "accuracy : 0.8517857142857143\n",
      "spes     : 0.8901960784313725\n",
      "sens     : 0.365\n",
      "auc      : 0.6275980392156862\n",
      "------------------------------------------------\n",
      "parameters : [0.2, 3, 1000, 1, 1, 0.75, 1, 9, 0.5, 0, 0.8]\n",
      "accuracy : 0.8464285714285714\n",
      "spes     : 0.8844268476621417\n",
      "sens     : 0.365\n",
      "auc      : 0.6247134238310709\n",
      "------------------------------------------------\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.62:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/        \n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.2],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[2,3,4,5],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[0,0.5,1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], #0.5-1\n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[10,11,12],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46656\n",
      "46655\r"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0.05, 0.9]\n",
      "0.8482142857142857\n",
      "0.8845022624434389\n",
      "0.395\n",
      "0.6397511312217194\n"
     ]
    }
   ],
   "source": [
    "print(max_params)\n",
    "print(max_acc)\n",
    "print(max_spes)\n",
    "print(max_sens)\n",
    "print(max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters : [0.2, 3, 1000, 1, 1, 1, 1.5, 12, 0.75, 0, 0.9]\n",
      "accuracy : 0.8089285714285714\n",
      "spes     : 0.840158371040724\n",
      "sens     : 0.42\n",
      "auc      : 0.630079185520362\n",
      "------------------------------------------------\n",
      "parameters : [0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0, 0.9]\n",
      "accuracy : 0.8553571428571429\n",
      "spes     : 0.8941553544494721\n",
      "sens     : 0.37\n",
      "auc      : 0.6320776772247361\n",
      "------------------------------------------------\n",
      "parameters : [0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0.05, 0.9]\n",
      "accuracy : 0.8482142857142857\n",
      "spes     : 0.8845022624434389\n",
      "sens     : 0.395\n",
      "auc      : 0.6397511312217194\n",
      "------------------------------------------------\n",
      "parameters : [0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0.2, 0.9]\n",
      "accuracy : 0.8571428571428572\n",
      "spes     : 0.8960784313725491\n",
      "sens     : 0.37\n",
      "auc      : 0.6330392156862745\n",
      "------------------------------------------------\n",
      "parameters : [0.2, 4, 1000, 2, 1, 0.5, 2, 10, 1.0, 0, 0.9]\n",
      "accuracy : 0.8535714285714285\n",
      "spes     : 0.8921945701357467\n",
      "sens     : 0.37\n",
      "auc      : 0.6310972850678733\n",
      "------------------------------------------------\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Τυπώνονται περιπτώσεις που accuracy>0.6 και specificity>0.6 και sensitivity>0.6 και auc>0.6\n",
    "s = 0\n",
    "for i in range(len(best_params)):\n",
    "    if best_params[i][4] > 0.63:\n",
    "        print(\"parameters :\",best_params[i][0])\n",
    "        print(\"accuracy :\",best_params[i][1])\n",
    "        print(\"spes     :\",best_params[i][2])\n",
    "        print(\"sens     :\",best_params[i][3])\n",
    "        print(\"auc      :\",best_params[i][4])\n",
    "        print(\"------------------------------------------------\")\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters : [0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0.05, 0.9]\n",
    "accuracy : 0.8482142857142857\n",
    "spes     : 0.8845022624434389\n",
    "sens     : 0.395\n",
    "auc      : 0.6397511312217194\n",
    "    \n",
    "parameters : [0.2, 3, 1000, 1, 0.5, 0.75, 1, 9, 0.5, 0.05, 0.8]\n",
    "accuracy : 0.8517857142857143\n",
    "spes     : 0.8901960784313725\n",
    "sens     : 0.365\n",
    "auc      : 0.6275980392156862\n",
    "    \n",
    "parameters : [0.2, 4, 1000, 2, 0.5, 0.5, 2, 10, 1.0, 0.2, 0.9]\n",
    "accuracy : 0.8571428571428572\n",
    "spes     : 0.8960784313725491\n",
    "sens     : 0.37\n",
    "auc      : 0.6330392156862745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.4],  \n",
    "                    \"max_depth\"        :[2,3,4,5,6,7],  \n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4,5,6],         \n",
    "                    \"gamma\"            :[0,0.5,1],           \n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], \n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], \n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.3], \n",
    "                    \"max_depth\"        :[2,3,4],  \n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4,5,6],         \n",
    "                    \"gamma\"            :[0,0.5,1],            \n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], \n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], \n",
    "                    \"scale_pos_weight\" :[3,4,5,6,7,8],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2,0.3],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n",
    "\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.2],  \n",
    "                    \"max_depth\"        :[2,3,4,5],  \n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4],         \n",
    "                    \"gamma\"            :[0,0.5,1],            \n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], \n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], \n",
    "                    \"scale_pos_weight\" :[4,5,6,7,8,9,10,11,12],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }\n",
    "params = {\n",
    "                    \"learning_rate\"    :[0.1],  \n",
    "                    \"max_depth\"        :[2,3,4,5,6],  \n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1,2,3,4,5,6],         \n",
    "                    \"gamma\"            :[0,0.5,1],            \n",
    "                    \"colsample_bylevel\" :[0.5,0.75,1], \n",
    "                     \"reg_lambda\"      :[1, 1.5, 2], \n",
    "                    \"scale_pos_weight\" :[3,4,5,6,7,8,9],\n",
    "                    \"colsample_bytree\" :[0.5,0.75,1.0],\n",
    "                    \"reg_alpha\"        :[0, 0.05,0.1,0.2],\n",
    "                    \"subsample\"        :[0.8,0.9,1.0]\n",
    "    \n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
