{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('CVD dataset-plin-7-9.csv') #διαβάζω το dataset που δεν περιλαμβανει τα features 7 και 9\n",
    "data=dataset.iloc[:, :].values\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 14].values\n",
    "\n",
    "rows = len(data)    # 3 rows in your example\n",
    "cols = len(data[0])\n",
    "print(rows)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "dataNoCvd = data[~(data[:,14] > 0.0)] #χωρίζω τα data σε 2 πίνακες, ο ένας με τα cvd ο άλλος με τα όχι cvd\n",
    "dataCvd = data[~(data[:,14] < 1.0)]\n",
    "rowsNoCvd = len(dataNoCvd)    \n",
    "rowsCvd = len(dataCvd)\n",
    "print(rowsNoCvd)\n",
    "print(rowsCvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Testing Validation sets\n",
    "\n",
    "Τα instances με cvd είναι 41 και χωρίς cvd είναι 519, συνολικά είναι δηλαδή 560. Άρα στο 10-fold cross validation το test set θα περιλαμβάνει 56 instances και τα υπόλοιπα 504 θα διατεθούν για το training. Όμως επειδή το 10% του training θα δωθεί στο validation set αυτό σημαίνει ότι τελικά 50 instances θα ανήκουν στο validation set και με τα υπόλοιπα 454 θα γίνεται το training.\n",
    "\n",
    "### Testing\n",
    "41//10=4 και υπόλοιπο 1\n",
    "519//10=51 και υπόλοιπο 9 \n",
    "Γιαυτό τα πρώτα 9 test set θα πάρουν από ένα extra NoCvd instance άρα θα έχουν NoCvd:52 Cvd:4\n",
    "το 10ο test set θα πάρει το  extra Cvd instance άρα θα έχει NoCvd:51 Cvd:5\n",
    "\n",
    "### Validation\n",
    "Το validation set θα έχει όπως είπαμε 50 instances και σταθερά NoCvd:46 Cvd:4\n",
    "Για να φτιάξουμε το validation set για κάθε fold θα παίρνουμε κάθε φορά τα επόμενα 46 instances από αυτά που πήραμε για το test set από τον πίνακα που θα περιέχει όλα τα instances χωρίς cvd και τα επόμενα 4 instances από αυτά που πήραμε για το test set από τον πίνακα που θα περιέχει όλα τα instances με cvd. Μόνο στην περίπτωση του 10ου fold θα πάρουμε τα 46 και τα 4 instances που προηγούνται των instances που πήραμε για το test set και αυτό γιατί δεν θα υπάρχουν επόμενα instances για να τα πάρουμε. Το ακόλουθο σχήμα δείχνει πώς γίνεται ο χωρισμός στην περίπτωση των 1,2,9 και 10 fold.\n",
    "\n",
    "### Training \n",
    "Όσα instances περισσεύουν από το test και validation set. Άρα ο συνολικός του αριθμός θα είναι 454 και στα πρώτα 9 folds θα έχει NoCvd:421 Cvd:33 και στο 10ο fold θα έχει NoCvd:422 και Cvd:32\n",
    "\n",
    "<!-- <img src=\"fold-1-2.png\"> -->\n",
    "<img src=\"fold-1-2-site.svg\">\n",
    "<img src=\"fold-9-10-site.svg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NoCvd_limitsArray(i,DownNoCvd, UpNoCvd, fold_NoCvd_total, fold_NoCvd_residue):\n",
    "    if i>0 :\n",
    "        DownNoCvd = UpNoCvd\n",
    "        UpNoCvd= fold_NoCvd_total+UpNoCvd\n",
    "    if i < fold_NoCvd_residue :\n",
    "        UpNoCvd+= 1\n",
    "    return   DownNoCvd, UpNoCvd   \n",
    " \n",
    "def find_Cvd_limitsArray(i,DownCvd, UpCvd, fold_Cvd_total, fold_Cvd_residue,cv):\n",
    "    if i>0 :\n",
    "        DownCvd = UpCvd\n",
    "        UpCvd= fold_Cvd_total+UpCvd\n",
    "    if i >= cv - fold_Cvd_residue :\n",
    "         UpCvd+= 1     \n",
    "    return   DownCvd, UpCvd  \n",
    "\n",
    "def find_testValSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd):\n",
    "    temp1=dataNoCvd[DownNoCvd:UpNoCvd,:]\n",
    "    temp2=dataCvd[DownCvd:UpCvd,:]\n",
    "    temp3=np.concatenate((temp1, temp2))\n",
    "    return temp3\n",
    "\n",
    "def find_trainSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd):\n",
    "    temp1 = np.delete(dataNoCvd, slice(DownNoCvd, UpNoCvd), axis=0)\n",
    "    temp2 = np.delete(dataCvd, slice(DownCvd, UpCvd), axis=0)\n",
    "    temp3 = np.concatenate((temp1, temp2))\n",
    "    return temp1, temp2, temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_sets(cv,dataNoCvd,dataCvd,val_ratio):\n",
    "    # cv= αριθμός των folds, κάνω 10-fold cross validation γιαυτό το έχω θέσει 10\n",
    "    # val_ratio= το ποσοστό του training set που θα γίνει validation set, το έβαλα 10%\n",
    "    test_total = []\n",
    "    train_total = []\n",
    "    train_total_Cvd = []\n",
    "    train_total_NoCvd = []\n",
    "    validation_total = []\n",
    "    \n",
    "    #στόχος είναι να χωρίσουμε τα δεδομένα σε 10 folds με ποσοστό instances με cvd περιπου 7%, το 1 fold θα                                \n",
    "    #χρησιμοποιείται για test και τα άλλα 9 θα ενωνονται και θα χρησιμοποιούνται για train-validation\n",
    "    \n",
    "    rowsNoCvd = len(dataNoCvd)    # βρίσκω τον αριθμό των instances χωρίς cvd\n",
    "    rowsCvd = len(dataCvd)        # βρίσκω τον αριθμό των instances με cvd\n",
    "\n",
    "    #fold_Cvd_total = αριθμός των instances με cvd που θα μπουν  σίγουρα στο 1 fold = 4\n",
    "    fold_Cvd_total = rowsCvd//cv \n",
    "    #fold_Cvd_residue = το υπόλοιπο των instances που πρέπει να το μοιράσουμε στα 10 folds, δηλαδη κάποια \n",
    "    #θα έχουν ένα instance με cvd παραπάνω = 1\n",
    "    fold_Cvd_residue= rowsCvd%cv\n",
    "    print(\"fold_Cvd_total  :\",fold_Cvd_total,\" fold_Cvd_residue  :\",fold_Cvd_residue)\n",
    "\n",
    "    #fold_NoCvd_total = αριθμός των instances χωρίς cvd που θα μπουν  σίγουρα στο 1 fold = 51\n",
    "    fold_NoCvd_total = rowsNoCvd//cv\n",
    "    #fold_NoCvd_residue = το υπόλοιπο των instances που πρέπει να το μοιράσουμε στα 10 folds, δηλαδη κάποια \n",
    "    #θα έχουν ένα instance χωρίς cvd παραπάνω = 9\n",
    "    fold_NoCvd_residue= rowsNoCvd%cv\n",
    "    print(\"fold_NoCvd_total:\",fold_NoCvd_total,\"fold_NoCvd_residue:\",fold_NoCvd_residue)\n",
    "    \n",
    "    #Cvd_val= αριθμός instances με cvd που θα μπει στο validation set,το train set αποτελείται από 504 instances  \n",
    "    #από αυτά το 7% είναι cvd, εμείς από το 7% θα πάρουμε το 10% για το validatio set\n",
    "    Cvd_val = round(504*val_ratio*(rowsCvd/len(data)))\n",
    "    #504*val_ratio= ο συνολικός αριθμός των instances  με του validation set, άρα αν από αυτόν αφαιρέσουμε \n",
    "    #το Cvd_val θα πάρουμε των αριθμό των instances χωρίς cvd που θα μπουν στο validation set\n",
    "    noCvd_val = round(504*val_ratio)-Cvd_val\n",
    "    \n",
    "    #dataNoCvd= [0 1 2 .... 517 518] αυτοί είναι οι δείκτες του πίνακα με όλα τα NoCvd instances, τα  DownNoCvd και\n",
    "    # UpNoCvd θα είναι οι δείκτες στους οποίους θα γίνεται το χώρισμα του πίνακα dataNoCvd κάθε φορά προκειμένου\n",
    "    # να πάρουμε ένα fold, DownNoCvd=κάτω όριο, UpNoCvd= πάνω όριο, ξεκινάμε με DownNoCvd=0(από την αρχή του πίνακα)\n",
    "    # UpNoCvd = fold_NoCvd_total(αριθμός NoCvd instances που θα μπουν σίγουρα στο fold)\n",
    "    #\n",
    "    #dataCvd= [0 1 2.. 39 40] δείκτες του πίνακα dataCvd, με την ίδια λογική με πριν DownCvd=0=κάτω όριο-δείκτης\n",
    "    # UpCvd= άνω όριο-δείκτης=fold_Cvd_total(αριθμός Cvd instances που θα μπουν σίγουρα στο fold)\n",
    "    DownNoCvd=0\n",
    "    DownCvd=0\n",
    "    UpNoCvd = fold_NoCvd_total\n",
    "    UpCvd = fold_Cvd_total\n",
    "    #τα όρια αυτά θα αλλάξουν 10 φορές, όσα είναι και τα fold \n",
    "    \n",
    "    for i in range(cv):\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_val = []\n",
    "        y_val = []\n",
    "        \n",
    "        #find_NoCvd_limitsArray = βρίσκει τα όρια του dataNoCvd πίνακα για το i fold\n",
    "        DownNoCvd, UpNoCvd = find_NoCvd_limitsArray(i, DownNoCvd, UpNoCvd, fold_NoCvd_total, fold_NoCvd_residue)\n",
    "        #find_Cvd_limitsArray = βρίσκει τα όρια του dataCvd πίνακα για το i fold\n",
    "        DownCvd, UpCvd = find_Cvd_limitsArray(i, DownCvd, UpCvd, fold_Cvd_total, fold_Cvd_residue,cv)\n",
    "\n",
    "        #find_testValSubset = επιστρέφει τον πίκακα test για το i-fold\n",
    "        testSubset_total = find_testValSubset(DownNoCvd,UpNoCvd,DownCvd,UpCvd)        \n",
    "        \n",
    "        if i!=9:\n",
    "        #όταν δεν είμαστε στο 10ο fold(ξεκινάμε από 0) παίρνουμε τα επόμενα 56 και 4 instaces για το validation set\n",
    "            validationSubset_total = find_testValSubset(UpNoCvd,UpNoCvd+noCvd_val,UpCvd,UpCvd+Cvd_val)\n",
    "            trainSubset_NoCvd ,trainSubset_Cvd ,trainSubset_total = find_trainSubset(DownNoCvd,UpNoCvd+noCvd_val,DownCvd,UpCvd+Cvd_val)\n",
    "        else:\n",
    "        #όταν είμαστε στο 10ο fold παίρνουμε τα προηγούμενα 56 και 4 instaces για το validation set\n",
    "            validationSubset_total = find_testValSubset(DownNoCvd-noCvd_val,DownNoCvd,DownCvd-Cvd_val,DownCvd)\n",
    "            trainSubset_NoCvd ,trainSubset_Cvd ,trainSubset_total = find_trainSubset(DownNoCvd-noCvd_val,UpNoCvd,DownCvd-Cvd_val,UpCvd)\n",
    "    \n",
    "    #creating X_train, y_train, X_test, y_test\n",
    "        #για να δημιουργήσω το X_test αφαιρώ απλά την τελευταία στήλη\n",
    "        X_test.append(np.delete(testSubset_total, 14, axis=1))\n",
    "        y_test_temp = np.delete(testSubset_total, slice(0, 14), axis=1)\n",
    "        #για το y_test κρατάω μόνο την τελευταία στήλη \n",
    "        y_test.append(np.reshape(y_test_temp, len(y_test_temp)))\n",
    "        #οι ακόλουθες γραμμές κώδικα είναι για να φέρω τα X_test και y_test στην μορφή πίνακα που θέλω\n",
    "        X_test_temp = np.array(X_test)\n",
    "        X_test = X_test_temp[0]\n",
    "        y_test_temp = np.array(y_test)\n",
    "        y_test = y_test_temp[0]\n",
    "        \n",
    "        #για να δημιουργήσω το X_val αφαιρώ απλά την τελευταία στήλη\n",
    "        X_val.append(np.delete(validationSubset_total, 14, axis=1))\n",
    "        y_val_temp = np.delete(validationSubset_total, slice(0, 14), axis=1)\n",
    "        #για το y_val κρατάω μόνο την τελευταία στήλη \n",
    "        y_val.append(np.reshape(y_val_temp, len(y_val_temp)))\n",
    "        X_val_temp = np.array(X_val)\n",
    "        X_val = X_val_temp[0]\n",
    "        y_val_temp = np.array(y_val)\n",
    "        y_val = y_val_temp[0]\n",
    "        \n",
    "        #για να δημιουργήσω το X_train αφαιρώ απλά την τελευταία στήλη\n",
    "        X_train.append(np.delete(trainSubset_total, 14, axis=1))\n",
    "        y_train_temp = np.delete(trainSubset_total, slice(0, 14), axis=1)\n",
    "        #για το y_train κρατάω μόνο την τελευταία στήλη \n",
    "        y_train.append(np.reshape(y_train_temp, len(y_train_temp)))\n",
    "        X_train_temp = np.array(X_train)\n",
    "        X_train = X_train_temp[0]\n",
    "        y_train_temp = np.array(y_train)\n",
    "        y_train = y_train_temp[0]\n",
    "        \n",
    "    #αποθηκεύω τα X_test,y_test στον πίνακα test_total οπότε στην i-οστή θέση θα είναι τα X_test,y_test για το i fold \n",
    "    #το ίδιο κάνω και με τους πίνακες validation_total και train_total\n",
    "        test_total.append([X_test,y_test])\n",
    "        validation_total.append([X_val,y_val])\n",
    "        train_total.append([X_train,y_train]) \n",
    "    #train_total_NoCvd:αποθηκεύω τα instances χωρίς Cvd πουθα χρησιμοποιηθούν για training όταν θα είμαστε στο i-fold\n",
    "        train_total_NoCvd.append(trainSubset_NoCvd)\n",
    "    #train_total_Cvd:αποθηκεύω τα instances με Cvd πουθα χρησιμοποιηθούν για training όταν θα είμαστε στο i-fold\n",
    "        train_total_Cvd.append(trainSubset_Cvd)\n",
    "    return train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_Cvd_total  : 4  fold_Cvd_residue  : 1\n",
      "fold_NoCvd_total: 51 fold_NoCvd_residue: 9\n"
     ]
    }
   ],
   "source": [
    "train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd = create_train_test_sets(10,dataNoCvd,dataCvd,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07268722466960352\n",
      "ratio in test set: 0.07142857142857142\n",
      "ratio in validation set: 0.08\n",
      "454\n",
      "ratio in train set: 0.07048458149779736\n",
      "ratio in test set: 0.08928571428571429\n",
      "ratio in validation set: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Chech ratio in each train and test set and validation set\n",
    "def find_ratio(index_list):\n",
    "    one = 0\n",
    "    lenght=len(index_list[0])\n",
    "    for i in range(lenght):\n",
    "#         print(index_list[1])\n",
    "        if index_list[1][i] == 1.0 :\n",
    "            one+= 1\n",
    "    ratio = one/lenght\n",
    "    return ratio\n",
    "\n",
    "for i in range(10):\n",
    "    print(len(train_total[i][0]))\n",
    "    ratio = find_ratio(train_total[i])\n",
    "    print(\"ratio in train set:\", ratio)\n",
    "    ratio = find_ratio(test_total[i])\n",
    "    print(\"ratio in test set:\", ratio)\n",
    "    ratio = find_ratio(validation_total[i])\n",
    "    print(\"ratio in validation set:\", ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def my_fit(ratio,dataNoCvd,dataCvd, validation_total, params):   \n",
    "    Subarray=[]\n",
    "    models = []\n",
    "    \n",
    "    rowsNoCvd = len(dataNoCvd)    \n",
    "    rowsCvd = len(dataCvd)\n",
    "\n",
    "#Για ratio 1:2 πρέπει να φτιαχτούν 6 μοντέλα\n",
    "    numOfSubsamples = rowsNoCvd//(rowsCvd*ratio)\n",
    "    numOfSubsamples= int(numOfSubsamples)\n",
    "    SubNoCvd = rowsNoCvd//numOfSubsamples\n",
    "    residue = rowsNoCvd- SubNoCvd*numOfSubsamples\n",
    "\n",
    "\n",
    "    Up = 0\n",
    "    valid_preds = []\n",
    "\n",
    "    for i in range(numOfSubsamples):\n",
    "        classifier = XGBClassifier(base_score=params[11], booster='gbtree', colsample_bylevel=params[5],\n",
    "                  colsample_bynode=params[12], colsample_bytree=params[8], gamma=params[4],\n",
    "                  learning_rate=params[0], max_delta_step=params[13], max_depth=params[1],\n",
    "                  min_child_weight=params[3], missing=None, n_estimators=params[2], n_jobs=1,\n",
    "                  nthread=None, objective='binary:logistic', random_state=0,\n",
    "                  reg_alpha=params[9], reg_lambda=params[6], scale_pos_weight=params[7], seed=None,\n",
    "                  silent=None, subsample=params[10], verbosity=1)\n",
    "\n",
    "#για να φτιάξουμε το training set αφού τα μοντέλα είναι 6 πρέπει να χωρίσουμε τα instances NoCvd στα 6\n",
    "#στα πρώτα 9-fold τα NoCvd instances είναι 421, άρα 421//6=70 με υπόλοιπο 1\n",
    "#στο 10ο fold τα NoCvd instances είναι 422, άρα 422//6=70 με υπόλοιπο 2\n",
    "#τα υπόλοιπα μπαίνουν στα πρώτα μοντέλα δηλαδή στα πρώτα 9-fold το πρώτο μοντέλο θα πάρει 71 NoCvd instances\n",
    "#και στο 10ο fold το πρώτο αλλά και το δεύτερο θα πάρουν 71 instances. Τα υπόλοιπα θα πάρουν από 70\n",
    "        Down = Up\n",
    "        Up= Up + SubNoCvd\n",
    "        if i < residue :\n",
    "            Up+= 1\n",
    "        \n",
    "        Sub1=dataNoCvd[Down:Up,:]\n",
    "        #φτίαχνουμε πίνακα με τα NoCvd instances που βρήκαμε ότι αναλογούν σε κάθε μοντέλο και με όλα τα Cvd instances\n",
    "        Sub2=np.concatenate((Sub1, dataCvd))\n",
    "        Subarray.append(Sub2)\n",
    "        \n",
    "    #Dividing to X and y of the previous traing set    \n",
    "        X=np.delete(Subarray[i], 14, axis=1)\n",
    "        y=np.delete(Subarray[i], slice(0, 14), axis=1)\n",
    "        y=np.reshape(y, len(y))\n",
    "        \n",
    "        X_val = validation_total[i][0]\n",
    "        y_val = validation_total[i][1]\n",
    "        \n",
    "        eval_set  = [(X,y), (X_val,y_val)]\n",
    "        #κάνουμε fit με χρήση early stopping\n",
    "        classifier.fit( X, y, eval_set=eval_set, eval_metric=\"auc\", early_stopping_rounds=40,verbose = False )\n",
    "  \n",
    "        print(\"model\",i,\" :\",classifier.best_iteration)\n",
    "        \n",
    "        #υπολογίζουμε το auc που έχει το μοντέλο για το validation set γιατί θα μας χρειαστεί στο weighted voting\n",
    "        auc_valid = roc_auc_score(y_val, classifier.predict(X_val))\n",
    "        #αποθηκεύουμε τα auc σε πίνακα για να τα επιστέψουμε όλα μαζί\n",
    "        valid_preds.append(auc_valid)\n",
    "\n",
    "        #ο κώδικας που ακολουθεί και είναι σε σχόλια είναι για να τυπώνει το πρώτο δένδρο κάθε μοντέλου xgboost\n",
    "#         plot_tree(classifier)     \n",
    "#         plt.rcParams[\"figure.figsize\"] = (40,7)\n",
    "#         plot_tree(classifier, num_trees=0, rankdir='LR')\n",
    "#         plt.show()\n",
    "\n",
    "        models.append(classifier)\n",
    "    return models,valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(models,X,auc_valid):\n",
    "    y_pred = []\n",
    "    y_pred_models = []\n",
    "    \n",
    "    models_size = len(models)\n",
    "    X_size = len(X)\n",
    "            \n",
    "    for i in range(models_size):\n",
    "        y_pred_models.append(models[i].predict(X))\n",
    "       \n",
    "        \n",
    "    for j in range(X_size):\n",
    "        case = 0\n",
    "        for i in range(models_size):\n",
    "            if y_pred_models[i][j] == 1.0:\n",
    "                case+=1\n",
    "        if case >  models_size/2 :\n",
    "            y_pred.append(1.) \n",
    "        else:\n",
    "            y_pred.append(0.) \n",
    "            \n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted voting\n",
    "def weighted_voting(models,X,auc_valid):\n",
    "    y_pred = []\n",
    "    y_pred_models = []\n",
    "    sum_auc = 0\n",
    "    \n",
    "    models_size = len(models)\n",
    "    X_size = len(X)\n",
    "            \n",
    "    for i in range(models_size):\n",
    "        y_pred_models.append(models[i].predict(X))\n",
    "        sum_auc += auc_valid[i]\n",
    "       \n",
    "    for j in range(X_size):\n",
    "        case = 0\n",
    "        for i in range(models_size):\n",
    "            case += y_pred_models[i][j]*(auc_valid[i]/sum_auc)*100 #auc_valid[i]/sum_auc --> η δύναμη της ψήφου\n",
    "                                                                    #του μοντέλου\n",
    "\n",
    "#έβαλα case>56 και όχι case>50(επειδή έχω κάνει *100 πίο πάνω μου ήταν πιο εύκολο στην κατανόηση, αλλίως\n",
    "#θα έπρεπε να είναι case>0.5), διότι το case>56 έδινε καλύτερο τελικό auc              \n",
    "        if case >  56 :\n",
    "            y_pred.append(1.) \n",
    "        else:\n",
    "            y_pred.append(0.) \n",
    "            \n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "#https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix,roc_curve, roc_auc_score, accuracy_score\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "def my_cross_val( cv, train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd,params):\n",
    "    accuracy = []\n",
    "    specificity = []\n",
    "    sensitivity = []\n",
    "    auc = []\n",
    "    \n",
    "\n",
    "    for i in range(cv):\n",
    "        print(\"----------------\",i,\"- fold -----------------------\")\n",
    "        print(\"                  Estimators\")\n",
    "        #από τον πίνακα test_total παίρνω τα X_test,y_test για το i-fold\n",
    "        X_test = test_total[i][0]\n",
    "        y_test = test_total[i][1]\n",
    "        \n",
    "        #εφαρμόζω fit που μου επιστέφει το ensemble μοντέλο και τις επιδόσεις-auc του κάθε μοντέλου xgboost\n",
    "        #που υπολογίζονται από τα validation set,από τα οποία αποτελείται το ensemble μοντέλο\n",
    "        models,auc_valid = my_fit( 2, train_total_NoCvd[i], train_total_Cvd[i], validation_total,params)\n",
    "\n",
    "        #εφαρμόζουμε weighted voting για να βρούμε την πρόβλεψη του ensemble model\n",
    "        #στο weighted voting θα έχουν πιο ισχυρή ψήφο τα μοντέλα με μεγαλύτερο auc στο validation set \n",
    "        y_pred = weighted_voting(models,X_test,auc_valid)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        total1=sum(sum(cm))\n",
    "        #####from confusion matrix calculate accuracy\n",
    "        accuracy1=(cm[0,0]+cm[1,1])/total1\n",
    "        \n",
    "#         accuracy1=accuracy_score(y_test, y_pred) #άλλος τρόπος για υπολογισμό accuracy\n",
    "\n",
    "        specificity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "\n",
    "        sensitivity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "        \n",
    "        auc1 = roc_auc_score(y_test, y_pred)\n",
    "        print(auc1)\n",
    "        accuracy.append(accuracy1)\n",
    "        specificity.append(specificity1)\n",
    "        sensitivity.append(sensitivity1) \n",
    "        auc.append(auc1)\n",
    "    #επιστρέφουμε πίνακες και με τα 10 accuracy, specificity, sensitivity, auc που προκύπτουν από το 10 fold cross\n",
    "    #validation\n",
    "    return accuracy, specificity, sensitivity, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-all-possible-permutations-of-n-lists/\n",
    "\n",
    "def compute_comb(params):\n",
    "    \n",
    "    # initializing lists \n",
    "    list1 = params.get(\"learning_rate\")\n",
    "    list2 = params.get(\"max_depth\")\n",
    "    list3 = params.get(\"n_estimators\") \n",
    "    list4 = params.get(\"min_child_weight\")\n",
    "    list5 = params.get(\"gamma\")    \n",
    "    list6 = params.get(\"colsample_bylevel\")\n",
    "    list7 = params.get(\"reg_lambda\") \n",
    "    list8 = params.get(\"scale_pos_weight\")\n",
    "    list9 = params.get(\"colsample_bytree\")\n",
    "    list10 = params.get(\"reg_alpha\")\n",
    "    list11 = params.get(\"subsample\")\n",
    "    list12 = params.get(\"base_score\")\n",
    "    list13 = params.get(\"colsample_bynode\")\n",
    "    list14 = params.get(\"max_delta_step\")\n",
    "    \n",
    "    # to compute all possible permutations \n",
    "    res = [[i, j, k, l, m, n, o, p,q,r,s,t, u, v] for i in list1  \n",
    "                                                  for j in list2 \n",
    "                                                  for k in list3 \n",
    "                                                  for l in list4 \n",
    "                                                  for m in list5 \n",
    "                                                  for n in list6 \n",
    "                                                  for o in list7\n",
    "                                                  for p in list8\n",
    "                                                  for q in list9\n",
    "                                                  for r in list10\n",
    "                                                  for s in list11\n",
    "                                                  for t in list12\n",
    "                                                  for u in list13\n",
    "                                                  for v in list14] \n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class style:\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix,roc_curve, roc_auc_score, accuracy_score\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "from statistics import mean\n",
    "\n",
    "def gridsearch(params):\n",
    "    max_sens = 0\n",
    "    max_spes = 0\n",
    "    max_acc = 0\n",
    "    best_params = []\n",
    "    max_params = []\n",
    "    max_auc = 0\n",
    "    #compute_comb = υπολογίζει όλους τους συνδυασμους των παραμέτρων που της δώσαμε να ελέγξει\n",
    "    combs = compute_comb(params)\n",
    "    print(len(combs))\n",
    "    \n",
    "    #για κάθε έναν συνδυασμό θα κάνουμε cross validation\n",
    "    for j in range(len(combs)):\n",
    "        print(j)\n",
    "        accuracy, specificity, sensitivity, auc = my_cross_val( 10, train_total, test_total, validation_total, train_total_NoCvd, train_total_Cvd,combs[j])\n",
    "        if mean(auc)>0.65:\n",
    "            print(style.BOLD + \"----------------------------------------------------------------\"+ style.END)\n",
    "            print(combs[j])\n",
    "            print (style.BOLD + 'accuracy    ' + style.END, mean(accuracy))\n",
    "            print (style.BOLD + 'specificity ' + style.END, mean(specificity))\n",
    "            print (style.BOLD + 'sensitivity ' + style.END, mean(sensitivity))\n",
    "            print (style.BOLD + 'auc         ' + style.END, mean(auc))\n",
    "            print(style.BOLD + \"----------------------------------------------------------------\"+ style.END)\n",
    "        \n",
    "        #ο πίνακας best_params θα περιέχει όλα τα αποτελέσματα όλων των συνδυασμών για να μπορούμε στο τέλος\n",
    "        #της gridsearch να βρούμε τα καλύτερα\n",
    "        #βλέπουμε ότι γίνεται αποθήκευση των mean γιατί η my_cross_val πιστρέφουμε πίνακες και με τα \n",
    "        #10 accuracy, specificity, sensitivity, auc που προκύπτουν από το 10 fold cross validation\n",
    "        best_params.append([combs[j],mean(accuracy),mean(specificity),mean(sensitivity),mean(auc)])\n",
    "        #αποθηκεύουμε τον συνδυασμό των παραμέτρων που μας δίνει το καλύτερο auc\n",
    "        if mean(auc)> max_auc:\n",
    "            max_sens = mean(sensitivity)\n",
    "            max_spes = mean(specificity)\n",
    "            max_acc = mean(accuracy)\n",
    "            max_auc = mean(auc)\n",
    "            max_params = combs[j]\n",
    "    return max_sens, max_params, max_spes, max_acc, max_auc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                    \"learning_rate\"    :[0.3],  #0.01-0.2 Makes the model more robust by shrinking the weights on each step\n",
    "                    \"max_depth\"        :[3],  #3-10 control over-fitting as higher depth will allow model to learn relations very specific to a particular sample\n",
    "                    \"n_estimators\"     :[1000],\n",
    "                    \"min_child_weight\" :[1],         #0.5-1 small values might lead to under-fitting\n",
    "                    \"gamma\"            :[1],            #Makes the algorithm conservative --> No overfitting\n",
    "                    \"colsample_bylevel\" :[0.75], #0.5-1\n",
    "                     \"reg_lambda\"      :[2], #  it should be explored to reduce overfitting.\n",
    "                    \"scale_pos_weight\" :[3],\n",
    "                    \"colsample_bytree\" :[0.5],\n",
    "                    \"reg_alpha\"        :[0.2],\n",
    "                    \"subsample\"        :[0.8],\n",
    "                    \"base_score\"       :[0.5],\n",
    "                    \"colsample_bynode\" :[1],\n",
    "                    \"max_delta_step\"   :[0]\n",
    "            \n",
    "        }\n",
    "# new features [3, 14, 13, 11, 15, 1, 2, 12, 10, 5, 6, 8, 0, 4]\n",
    "# [0.3, 3, 1000, 1, 1, 0.75, 2, 3, 0.5, 0.2, 0.8]\n",
    "# accuracy     0.725\n",
    "# specificity  0.7245852187028657\n",
    "# sensitivity  0.735\n",
    "# auc          0.7297926093514329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "---------------- 0 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 1\n",
      "model 1  : 23\n",
      "model 2  : 29\n",
      "model 3  : 27\n",
      "model 4  : 43\n",
      "model 5  : 55\n",
      "0.7692307692307692\n",
      "---------------- 1 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 32\n",
      "model 1  : 30\n",
      "model 2  : 61\n",
      "model 3  : 35\n",
      "model 4  : 27\n",
      "model 5  : 78\n",
      "0.6923076923076923\n",
      "---------------- 2 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 33\n",
      "model 1  : 19\n",
      "model 2  : 17\n",
      "model 3  : 21\n",
      "model 4  : 179\n",
      "model 5  : 6\n",
      "0.6442307692307693\n",
      "---------------- 3 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 66\n",
      "model 1  : 10\n",
      "model 2  : 111\n",
      "model 3  : 1\n",
      "model 4  : 129\n",
      "model 5  : 8\n",
      "0.7019230769230769\n",
      "---------------- 4 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 13\n",
      "model 1  : 46\n",
      "model 2  : 14\n",
      "model 3  : 32\n",
      "model 4  : 1\n",
      "model 5  : 7\n",
      "0.7403846153846154\n",
      "---------------- 5 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 25\n",
      "model 1  : 13\n",
      "model 2  : 17\n",
      "model 3  : 18\n",
      "model 4  : 1\n",
      "model 5  : 7\n",
      "0.7019230769230769\n",
      "---------------- 6 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 31\n",
      "model 1  : 21\n",
      "model 2  : 16\n",
      "model 3  : 21\n",
      "model 4  : 59\n",
      "model 5  : 6\n",
      "0.8461538461538461\n",
      "---------------- 7 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 72\n",
      "model 1  : 29\n",
      "model 2  : 13\n",
      "model 3  : 42\n",
      "model 4  : 51\n",
      "model 5  : 5\n",
      "0.7596153846153846\n",
      "---------------- 8 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 16\n",
      "model 1  : 32\n",
      "model 2  : 4\n",
      "model 3  : 114\n",
      "model 4  : 59\n",
      "model 5  : 56\n",
      "0.875\n",
      "---------------- 9 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 23\n",
      "model 1  : 28\n",
      "model 2  : 39\n",
      "model 3  : 8\n",
      "model 4  : 117\n",
      "model 5  : 104\n",
      "0.692156862745098\n",
      "\u001b[1m----------------------------------------------------------------\u001b[0m\n",
      "[0.3, 3, 1000, 1, 1, 0.75, 2, 3, 0.5, 0.2, 0.8, 0.5, 1, 0]\n",
      "\u001b[1maccuracy    \u001b[0m 0.7267857142857143\n",
      "\u001b[1mspecificity \u001b[0m 0.7245852187028657\n",
      "\u001b[1msensitivity \u001b[0m 0.76\n",
      "\u001b[1mauc         \u001b[0m 0.7422926093514328\n",
      "\u001b[1m----------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)\n",
    "#v=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "---------------- 0 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 1\n",
      "model 1  : 23\n",
      "model 2  : 29\n",
      "model 3  : 27\n",
      "model 4  : 43\n",
      "model 5  : 55\n",
      "0.7692307692307692\n",
      "---------------- 1 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 32\n",
      "model 1  : 30\n",
      "model 2  : 61\n",
      "model 3  : 35\n",
      "model 4  : 27\n",
      "model 5  : 31\n",
      "0.6923076923076923\n",
      "---------------- 2 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 33\n",
      "model 1  : 19\n",
      "model 2  : 17\n",
      "model 3  : 21\n",
      "model 4  : 107\n",
      "model 5  : 6\n",
      "0.6442307692307693\n",
      "---------------- 3 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 66\n",
      "model 1  : 10\n",
      "model 2  : 68\n",
      "model 3  : 1\n",
      "model 4  : 48\n",
      "model 5  : 8\n",
      "0.6826923076923078\n",
      "---------------- 4 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 13\n",
      "model 1  : 46\n",
      "model 2  : 14\n",
      "model 3  : 32\n",
      "model 4  : 1\n",
      "model 5  : 7\n",
      "0.7403846153846154\n",
      "---------------- 5 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 25\n",
      "model 1  : 13\n",
      "model 2  : 17\n",
      "model 3  : 18\n",
      "model 4  : 1\n",
      "model 5  : 7\n",
      "0.7019230769230769\n",
      "---------------- 6 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 31\n",
      "model 1  : 21\n",
      "model 2  : 16\n",
      "model 3  : 21\n",
      "model 4  : 11\n",
      "model 5  : 6\n",
      "0.8653846153846154\n",
      "---------------- 7 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 72\n",
      "model 1  : 29\n",
      "model 2  : 13\n",
      "model 3  : 42\n",
      "model 4  : 51\n",
      "model 5  : 5\n",
      "0.7596153846153846\n",
      "---------------- 8 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 16\n",
      "model 1  : 32\n",
      "model 2  : 4\n",
      "model 3  : 69\n",
      "model 4  : 59\n",
      "model 5  : 56\n",
      "0.8846153846153846\n",
      "---------------- 9 - fold -----------------------\n",
      "                  Estimators\n",
      "model 0  : 23\n",
      "model 1  : 28\n",
      "model 2  : 39\n",
      "model 3  : 8\n",
      "model 4  : 117\n",
      "model 5  : 58\n",
      "0.692156862745098\n",
      "\u001b[1m----------------------------------------------------------------\u001b[0m\n",
      "[0.3, 3, 1000, 1, 1, 0.75, 2, 3, 0.5, 0.2, 0.8, 0.5, 1, 0]\n",
      "\u001b[1maccuracy    \u001b[0m 0.7285714285714285\n",
      "\u001b[1mspecificity \u001b[0m 0.7265082956259427\n",
      "\u001b[1msensitivity \u001b[0m 0.76\n",
      "\u001b[1mauc         \u001b[0m 0.7432541478129714\n",
      "\u001b[1m----------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "max_sens ,max_params, max_spes, max_acc, max_auc, best_params = gridsearch(params)\n",
    "#v=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
